{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shipment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-54dd48f20ac6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mshipment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHousingException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mShipmentException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshipment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshipment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_entity\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataTransformationConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshipment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0martifact_entity\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataIngestionArtifact\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataValidationArtifact\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mDataTransformationArtifact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shipment'"
     ]
    }
   ],
   "source": [
    "from shipment.exception import HousingException, ShipmentException\n",
    "from shipment.logger import logging\n",
    "from shipment.entity.config_entity import DataTransformationConfig\n",
    "from shipment.entity.artifact_entity import DataIngestionArtifact,DataValidationArtifact, \\\n",
    "    DataTransformationArtifact\n",
    "from shipment.constant import *\n",
    "from shipment.util.util import read_yaml_file,save_object,save_numpy_array_data,load_data\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self,columns):\n",
    "        \"\"\"\n",
    "        FeatureGenerator Initialization\n",
    "        Scheduled Delivery Date: columns of type datetime  in the dataset\n",
    "        Delivered to Client Date: columns of type datetime  in the dataset\n",
    "\n",
    "        Genrated Feature\n",
    "        late_days_between_delivery_scheduled : subtraction of  Delivered to Client Date and Scheduled Delivery Date\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if SCHEDULED_DELIVERY_DATE_KEY in columns:\n",
    "                self.scheduled_delivery_date = SCHEDULED_DELIVERY_DATE_KEY\n",
    "\n",
    "            if DELIVERED_TO_CLIENT_DATE_KEY in columns:\n",
    "                self.delivered_to_client_date = DELIVERED_TO_CLIENT_DATE_KEY\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ShipmentException(e, sys) from e\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        try:\n",
    "            # train and test file path\n",
    "            df = pd.DataFrame(X)\n",
    "            logging.info(\"df columns: \",df.columns)\n",
    "\n",
    "            #scheduled = df[self.scheduled_delivery_date].apply(lambda x: pd.to_datetime(x,errors=\"coerce\"))\n",
    "            #delivered = df[self.delivered_to_client_date].apply(lambda x: pd.to_datetime(x,errors=\"coerce\"))\n",
    "\n",
    "            #df[\"late_days_between_delivery_scheduled\"] = delivered - scheduled\n",
    "            #df[\"late_days_between_delivery_scheduled\"] = df['late_days_between_delivery_scheduled'].apply(lambda x:str(x).split(\" \")[0]).astype('float')\n",
    "                                                                                         \n",
    "        except Exception as e:\n",
    "            raise ShipmentException(e, sys) from e\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "\n",
    "    def __init__(self, data_transformation_config: DataTransformationConfig,\n",
    "                 data_ingestion_artifact: DataIngestionArtifact,\n",
    "                 data_validation_artifact: DataValidationArtifact\n",
    "                 ):\n",
    "        try:\n",
    "            logging.info(f\"{'>>' * 30}Data Transformation log started.{'<<' * 30} \")\n",
    "            self.data_transformation_config= data_transformation_config\n",
    "            self.data_ingestion_artifact = data_ingestion_artifact\n",
    "            self.data_validation_artifact = data_validation_artifact\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ShipmentException(e,sys) from e\n",
    "\n",
    "\n",
    "    def get_data_transformer_object(self) -> ColumnTransformer:\n",
    "        try:\n",
    "            schema_file_path = self.data_validation_artifact.schema_file_path\n",
    "            \n",
    "            dataset_schema = read_yaml_file(file_path=schema_file_path)\n",
    "\n",
    "            numerical_columns = dataset_schema[DATASET_NUMERICAL_COLUMNS_KEY]\n",
    "            categorical_columns = dataset_schema[DATASET_CATEGORICAL_COLUMNS_KEY]\n",
    "            datetime_columns = dataset_schema[DATASET_DATETIME_COLUMNS_KEYS]\n",
    "\n",
    "            num_pipeline = Pipeline(steps=[\n",
    "                ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "                ('feature_generator',FeatureGenerator(\n",
    "                    columns=datetime_columns\n",
    "                )),\n",
    "                ('scaler',StandardScaler())\n",
    "            ])\n",
    "\n",
    "            cat_pipeline = Pipeline(steps=[\n",
    "                ('imputer',SimpleImputer(strategy=\"most_frequent\")),\n",
    "                ('one_hot_encoder',OneHotEncoder()),\n",
    "                ('scaler',StandardScaler(with_mean=False))\n",
    "            ])\n",
    "\n",
    "            logging.info(f\"Categorical columns : {categorical_columns}\")\n",
    "            logging.info(f\"Numerical columns : {numerical_columns}\")\n",
    "\n",
    "            preprocessing = ColumnTransformer([\n",
    "                ('num_pipeline',num_pipeline,numerical_columns),\n",
    "                ('cat_pipeline',cat_pipeline,categorical_columns)\n",
    "            ])\n",
    "\n",
    "            return preprocessing\n",
    "        except Exception as e:\n",
    "            raise ShipmentException(e,sys) from e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64a986a97bacbbb46df90e1cd1db6f5606b1be209c2d738a7cd60452d2dc1efa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
